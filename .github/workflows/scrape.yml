name: Job Scraper

on:
  schedule:
    # Run every 2 hours (Phase 2: was every 6 hours)
    - cron: "0 */2 * * *"
  workflow_dispatch:  # allow manual trigger from GitHub UI

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      # ── Checkout ────────────────────────────────────────────────────────────
      - name: Checkout repository
        uses: actions/checkout@v4

      # ── Python setup ────────────────────────────────────────────────────────
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: job_scraper/requirements.txt

      # ── Install Python dependencies ─────────────────────────────────────────
      - name: Install dependencies
        working-directory: job_scraper
        run: pip install -r requirements.txt

      # ── Install Playwright browsers ─────────────────────────────────────────
      - name: Install Playwright Chromium
        working-directory: job_scraper
        run: |
          # On Ubuntu 24.04, libasound2 was renamed to libasound2t64.
          # Playwright's --with-deps still requests the old name, so we install
          # chromium without --with-deps and handle deps separately.
          sudo apt-get update -qq
          sudo apt-get install -y --no-install-recommends \
            libasound2t64 libatk1.0-0 libatk-bridge2.0-0 libcups2 libdrm2 \
            libgbm1 libgtk-3-0 libnspr4 libnss3 libwayland-client0 libxcomposite1 \
            libxdamage1 libxfixes3 libxkbcommon0 libxrandr2 xdg-utils \
            fonts-liberation libglib2.0-0
          playwright install chromium

      # ── Write secrets to .env ───────────────────────────────────────────────
      - name: Write .env file
        working-directory: job_scraper
        env:
          GMAIL_ADDRESS:            ${{ secrets.GMAIL_ADDRESS }}
          GMAIL_APP_PASSWORD:       ${{ secrets.GMAIL_APP_PASSWORD }}
          ADZUNA_APP_ID:            ${{ secrets.ADZUNA_APP_ID }}
          ADZUNA_APP_KEY:           ${{ secrets.ADZUNA_APP_KEY }}
          JOOBLE_API_KEY:           ${{ secrets.JOOBLE_API_KEY }}
          NVIDIA_API_KEY:           ${{ secrets.NVIDIA_API_KEY }}
          SUPABASE_URL:             ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY:     ${{ secrets.SUPABASE_SERVICE_KEY }}
          LINKEDIN_EMAIL:           ${{ secrets.LINKEDIN_EMAIL }}
          LINKEDIN_PASSWORD:        ${{ secrets.LINKEDIN_PASSWORD }}
          USAJOBS_API_KEY:          ${{ secrets.USAJOBS_API_KEY }}
          ALERT_EMAIL_TO:           ${{ secrets.ALERT_EMAIL_TO }}
          GOOGLE_SPREADSHEET_ID:    ${{ secrets.GOOGLE_SPREADSHEET_ID }}
          TELEGRAM_BOT_TOKEN:       ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID:         ${{ secrets.TELEGRAM_CHAT_ID }}
        run: |
          cat > .env <<EOF
          GMAIL_ADDRESS=$GMAIL_ADDRESS
          GMAIL_APP_PASSWORD=$GMAIL_APP_PASSWORD
          ADZUNA_APP_ID=$ADZUNA_APP_ID
          ADZUNA_APP_KEY=$ADZUNA_APP_KEY
          JOOBLE_API_KEY=$JOOBLE_API_KEY
          NVIDIA_API_KEY=$NVIDIA_API_KEY
          SUPABASE_URL=$SUPABASE_URL
          SUPABASE_SERVICE_KEY=$SUPABASE_SERVICE_KEY
          LINKEDIN_EMAIL=$LINKEDIN_EMAIL
          LINKEDIN_PASSWORD=$LINKEDIN_PASSWORD
          USAJOBS_API_KEY=$USAJOBS_API_KEY
          ALERT_EMAIL_TO=$ALERT_EMAIL_TO
          GOOGLE_SPREADSHEET_ID=$GOOGLE_SPREADSHEET_ID
          TELEGRAM_BOT_TOKEN=$TELEGRAM_BOT_TOKEN
          TELEGRAM_CHAT_ID=$TELEGRAM_CHAT_ID
          EOF

      # ── Write Google service account JSON (if secret is set) ────────────────
      - name: Write Google service account JSON
        working-directory: job_scraper
        env:
          GOOGLE_SERVICE_ACCOUNT_JSON_CONTENT: ${{ secrets.GOOGLE_SERVICE_ACCOUNT_JSON }}
        run: |
          if [ -n "$GOOGLE_SERVICE_ACCOUNT_JSON_CONTENT" ]; then
            echo "$GOOGLE_SERVICE_ACCOUNT_JSON_CONTENT" > service_account.json
            echo "service_account.json written"
          else
            echo "GOOGLE_SERVICE_ACCOUNT_JSON secret not set — Sheets sync will be skipped"
          fi

      # ── Run the scraper ─────────────────────────────────────────────────────
      - name: Run job scraper
        working-directory: job_scraper
        run: python main.py

      # ── Upload SQLite DB as artifact ─────────────────────────────────────────
      - name: Upload database artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: jobs-db-${{ github.run_number }}
          path: job_scraper/jobs.db
          retention-days: 7

      # ── Upload log as artifact ───────────────────────────────────────────────
      - name: Upload scraper log
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: scraper-log-${{ github.run_number }}
          path: job_scraper/scraper.log
          retention-days: 3
